---
title: "大数据基础设施综述"
date: 2019-11-17T13:54:11+08:00
draft: false
---

早在1980年，未来学家托夫勒就在《第三次浪潮》之中就提出大数据的概念并赞誉 其为“第三次浪潮的华彩乐章”，然而，这在当时并没有引起人们的特别注意，但是随着社交网络、物联网、云计算的兴起，我们身边的数据规模越来越大，2014年，全世界的用户每天在Twitter上发布超过6.6亿条微博，在facebook发布1000万张以上的照片……根据IDC报告，2013年全球数据量为4.4ZB，2016年将达到12ZB而到了2020年，这个数字将达到40ZB，如果将这些数据刻到光盘上并摞成一堆的话，其高度将达到地球和月球之间距离的200倍。面对如此海量的，“大数据”时代正式到来。

什么是“大数据”，迄今没有公认的定义，IBM公司的观点认为，大数据应该满足规模性(Volume)、多样性(Variety)、实时性
(Velocity)，即”3V”要素[refs]；以IDC为代表的业界则认为大数据除了具备”3V”要素之外还需要具备第四“V”:价值性(Value);而NetApp公司则认为“大数据”应该包括分析(Analytic)带宽(Bandwidth)和内容(Content)即“ABC”特点[refs]。不管采用哪种定义，大数据本质都是工业传感器、互联网和物联网等产生的结构化、半结构化或者非结构化的数据的总和。人们通过对大数据的挖掘、处理以获得其中隐含的信息和知识，从而实现商业价值更好地为人们服务。而要对大数据进行挖掘、处理，就离不开大数据基础设施。本文对常用大数据处理系统做了分类，并对各种基础设施进行了简单的介绍，然后提出了现阶段大数据基础设施存在的问题，最后进行了总结。

# 大数据与大数据基础设施

## 大数据

据统计[ref]，2016年全球的数据量已经超过了14ZB， 并且到2020年，全球数据量将达到现在的3倍，达到40ZB。这些数据主要来源于三个方面：

* 传统IT企业、门户网站，传统IT企业开发、优化自身产品服务用户的同时，数据也源源不断不断产出，这方面产出的数据量占大约15%;
* 社交网络，近年来随着微信、Twitter等社交网络的兴起，互联网上信息不在仅仅是简单的文本了，UGC(用户自生成)内容、音频、视频图片等非结构信息逐渐大量充斥于网络中，其产出的数据量也相当可观；
* 物联网,物联网在近十年发展壮大，已经在我们生活中广泛普及，物联网设备往往带有许多传感器，不断地收集用户环境、位置、生活等各种各样的数据，这方面的数据量是增长最快的。

通过对大数据的分析，可以从中发掘出许多隐藏的信息，拿推荐系统中最经典的啤酒喝尿布案例来举例，“啤酒与尿布”的故事是营销届的神话，“啤酒”和“尿布”两个看上去没有关系的商品摆放在一起进行销售、并获得了很好的销售收益，这种现象就是卖场中商品之间的关联性，研究“啤酒与尿布”关联的方法就是通过对所有顾客的消费记录应用大数据处理技术得到的。根据统计到2020年，像这样与大数据直接相关的产业市场规模将达到5.3万亿美元，因此研究和应用大数据技术是非常有意义的。

然而，上文提到的大数据的数据量超过了任何传统数据处理系统的存储、处理能力，并且大数据类型多种多样，虽然价值很大但是价值密度很低，更重要的是大数据存在着真伪难辨的问题，即使最好的数据清洗方法也难以消除其中的不可预测性。

面对这些问题，首当其冲的就是Google、Facebook、Twitter等互联网公司[refs]，他们拥有着庞大的用户量，这些用户产生了史无前例庞大的数据，传统的数据处理基础设施对这样海量的数据束手无策，所以这些公司开始着手开发他们急需的适合于处理海量数据的大数据基础设施。当他们开发好这些工具之后，由于开源软件思维的影响，他们把这些工具的源码公布出来，和世界分享他们的成果。如此一来，全世界最优秀的科学家工程师都加入了大数据技术的开发中来。一段时间之后，大公司的员工们独立出来开始创业，新兴的大数据产业吸引了大量的天使投资人，这样，大数据基础设施的发展又向前推进了一步。

下面我们就对这些基础设施做简单的介绍。

## 大数据基础设施

大数据基础设施不是单单只有一种工具，而是结合了一系列的工具的工具栈系统。他们主要可以分成批量处理系统、流式数据处理系统、交互式数据处理系统和图数据处理系统四类。其中，批量数据处理系统针对静态数据的处理，流式数据处理系统和交互式数据处理系统针对的是实时数据的处理，而图数据处理系统即处理静态数据也处理实时数据。

### 批量数据处理系统

批量数据处理系统对实时性的要求不高，它采用的是先存储后计算的处理方式，因为不要求实时，所以它可以挖掘出数据集中隐含的模式并给出其中的含义从而制定明智的决策，正是因为这个原因，批量数据处理系统常常用于对准确性和全面性要求比较高的场合。

其中具有代表性的基础设施为根据谷歌发表的GFS(Google File System)和MapReduce模型两篇论文而开发出的Apache Hadoop。Apache Hadoop是一个提供分布式存储和批量数据计算服务的开源框架，它的核心由分布式文件存储系统HDFS和计算模型Mapreduce构成，并且，由于在Apache Hadoop 2.0中新加入了YARN资源管理系统，使得Apache Hadoop的概念不在局限于Hadoop框架本身，而成为了一个可扩展Pig, Hive, HBase等设施的生态系统。
![](http://7xkyov.com1.z0.glb.clouddn.com/16-6-17/48704352.jpg)

### 流式数据处理系统

近年来，流式数据处理系统得到了广泛认可，这类系统处理的数据特征为不宜持久稳定关系建模，而适宜瞬态关系建模，通俗讲就是需要对数据进行实时或者准实时处理。它的应用场景十分广泛，包括金融服务(量化交易)、网络监控、安全领域、电信数据管理、传感检测等。由于传统数据库管理系统(DBMS)并不是为快速连续存放数据单元且不支持连续查询等流数据处理的关键要素，所以其不能满足要求，而批量数据处理处理系统本身就不是实时系统同样不能满足要求。

为此，Google与2010年推出Dremel[refs]，Dremel是一个大规模系统。在一个PB级别的数据集上面，将任务缩短 到秒级，由此实时数据处理的大门正式打开。

流式数据处理系统要处理的数据可以想象成来自于一个无穷无尽的数据序列，这些数据来源各异、格式复杂，虽然流式数据往往带有时间或其他有序标签，但是他们实际不一定按序到达，所以如何处理物理顺序和逻辑顺序的不一致也是一个难点，另外，流式数据的流入量是随时间变化的，如何进行有弹性的处理也是一个要解决的难点。

流式处理系统主要有Twitter 的Storm，Facebook的Scribe， Spark Streaming, Linkedin 的Samza等。

1. Storm系统Storm是一套专门用于事件流处理的分布式计算框架，Storm的诞生可以追溯到当初由BackType公司开发的项目，这家市场营销情报企业于2011年被Twitter所收购。Twitter旋即将该项目转为开源并推向GitHub平台，不过Storm最终还是加入了Apache孵化器计划并于2014年9月正式成为Apache旗下的顶级项目之一。为了简化大规模数据处理机制，Storm在设计思路中充分考虑到大规模可扩展能力、利用一套“故障快速、自动重启”方案为处理提供容错性支持、从而有力地保证了每个元组都能切实得到处理。其流式处理作业被分发至不同类型的组件，Spout组件负责输入流传递到Blot组件，Blot组件负责对Spout传递的数据进行处理。许多Spout和Blot的组合结合起来构成一套有向无环图拓扑结构。可以将拓扑结构大致视为MapReduce在Hadoop当中所扮演的角色，只不过Storm的关注重点放在了实时、以流为基础的处理机制身上，因此其拓扑结构默认永远运行或者说直到手动中止。一旦拓扑流程启动，挟带着数据的流就会不断涌入系统并将数据交付给栓（而数据仍将在各栓之间循流程继续传递），而这也正是整个计算任务的主要实现方式。随着处理流程的推进，一个或者多个栓会把数据写入至数据库或者文件系统当中，并向另一套外部系统发出消息或者将处理获得的计算结果提供给用户。[refs](http://developer.51cto.com/art/201412/460116.htm)

1. Samzasamza是一个分布式的流式数据处理框架（streaming processing），它是基于Kafka(Linkedin开发的一个分布式的消息队列系统)来实现类实时的流式数据处理的。(准确的说，samza是通过模块化的形式来使用kafka的，因此可以构架在其他消息队列框架上，但出发点和默认实现是基于kafka)Samza的一个job的基本处理流程是一个用户任务从一个或多个输入流中读取数据，再输出到一个或多个输出流中，具体映射到kafka上就是从一个或多个topic读入数据，再写出到另一个或多个topic中去。多个job串联起来就完成了流式的数据处理流程。
![](http://img.blog.csdn.net/20130927100812234?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY29sb3JhbnQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)这种模式其实有点像MapReduce的过程，stream输入部分由kafka的partition决定了分区和task数目，类似于一个Map过程，输出时由用户task指定topic和分区（或者框架自动由Key决定分区），这相当于一次shuffle的过程，下一个job读取新的stream时，可以认为是一个reduce，也可以认为是下一个map过程的开始。不同之处在于job之间的串联无需等待上一个job的结束，类实时的消息分发机制决定了整个串联的job是连续不间断的，亦即流式的。[refs](http://blog.csdn.net/colorant/article/details/12082145)
2. Spark StreamingSpark Streaming是核心Spark API的一个扩展，它并不会像Storm那样一次一个地处理数据流，而是在处理前按时间间隔预先将其切分为一段一段的批处理作业。Spark针对持续性数据流的抽象称为DStream（DiscretizedStream），一个DStream是一个微批处理（micro-batching）的RDD（弹性分布式数据集）；而RDD则是一种分布式数据集，能够以两种方式并行运作，分别是任意函数和滑动窗口数据的转换。
![](http://img.ptcms.csdn.net/article/201503/09/54fcc92668e64.jpg)

针对上面几种流式数据处理框架，如果需要的是一个允许增量计算的高速事件处理系统，Storm是最佳选择，它可以应对你在客户端等待结果的同时，进一步进行分布式计算的需求，使用开箱即用的分布式RPC（DRPC）就可以了。如果需要状态持续，并且还有计划对图像数据的处理、机器学习相关或者访问SQL的话，Spark将是更好的选择。

### 交互式数据处理系统

许多场合，人们希望在对大数据的处理的过程可以有人为的介入，工作人员提出请求，交互式处理系统处理后返回结果然后引导工作人员继续下一步的操作。这样能够保证文件被及时修改，应对变化。

交互式处理系统主要包括两类：人机交互和用户之间交互。

传统的人机交互主要以关系数据库管理系统(DBMS)为主，由于其规模的局限性，今年来能够支持上千台服务器规模的Hive和Pig发展迅速。由于社交网络、即时通讯的兴起，互联网领域称为用户间交互最重要的应用场景，目前这方面用的最多的是NoSQL类型的数据库，比如HBase和MongoDB。

最近，由于Hive的性能和实时性问题，不少公司都提出了自己的交互数据处理解决方案，其中最有名的要数Google的Dremel和Apache Spark。

1. DremelDremel是Google研发的一款交互式数据处理系统，通过组建上千台的服务器，Dremel能够轻松将对PB级数据的处理时间压缩到秒级，它并不是MapReduce的替代品而是对Mapreduce查询能力不足的补充，所以它常用来处理MapReduce的结果集，同时，为了实现NoSQL难以做到的Join操作，Dremel采用了嵌套式的数据模型，并且提供了类SQL的交互式接口方便非开发人员使用。
2. SparkSpark由美国加州伯克利大学的AMPLab实验室开发的一款分布式集群计算框架，它开发于2009年，于2010年开源，并在2013年被捐赠给Apache项目。Spark通过在数据处理过程中成本更低的洗牌（Shuffle）方式，将MapReduce提升到一个更高的层次。利用内存数据存储和接近实时的处理能力，Spark比其他的大数据处理技术的性能要快很多倍。Spark将中间结果保存在内存中而不是将其写入磁盘，当需要多次处理同一数据集时，这一点特别实用。Spark的设计初衷就是既可以在内存中又可以在磁盘上工作的执行引擎。当内存中的数据不适用时，Spark操作符就会执行外部操作。Spark可以用于处理大于集群内存容量总和的数据集。Spark在交互式数据处理中的作用主要由Spark SQL 提供，Spark SQL可以通过JDBC API将Spark数据集暴露出去，而且还可以用传统的BI和可视化工具在Spark数据上执行类似SQL的查询。用户还可以用Spark SQL对不同格式的数据（如JSON，Parquet以及数据库等）执行ETL，将其转化，然后暴露给特定的查询。![](http://www.tutorialspoint.com/spark_sql/images/spark_sql_architecture.jpg)

### 图数据处理系统

近十几年来，随着互联网的普及和Web2.0技术的推动，网页数量增长迅猛， 据CNNIC统计，早在2010年仅中国网页规模就已经达到了600亿，并且保持着78.6%以上的年增长率。

网页的之间的结构正对应于图数据结构，每个网页相当于一个节点，网页之间的链接关系相当于节点之间的边。这样的数据有一下几个显著特征，一是节点之间的边随节点数量呈指数增加，二是数据之间具有较强的关联性，网页之间的链接往往是因为具有某种联系才存在的。

真实世界中实体规模的扩张， 导致对应的图数据规模迅速增长， 动辄有数十亿个顶点和上万亿条边。 单个图的规模通常包含10 亿个以上节点。 面对这样大规模的图，对海量数据处理技术提出了巨大挑战。

为了解决这个问题，许多公司都开发了自己的图数据处理系统,比如Neo4j,HyperGraghDB。

* Neo4j: Neo4j是一个高性能的,NOSQL图形数据库，它将结构化数据存储在网络上而不是表中。它是一个嵌入式的、基于磁盘的、具备完全的事务特性的Java持久化引擎，但是它将结构化数据存储在网络(从数学角度叫做图)上而不是表中。Neo4j也可以被看作是一个高性能的图引擎，该引擎具有成熟数据库的所有特性。程序员工作在一个面向对象的、灵活的网络结构下而不是严格、静态的表中——但是他们可以享受到具备完全的事务特性、企业级的数据库的所有好处。
* HyperGraphDB: HyperGraphDB是一套开源数据存储机制，并依托于BerkeleyDB数据库存在。HyperGraphDB的图形模型被称为直接式超图形。从数学角度来讲，超图形允许其一条边线指向两个以上的节点。HyperGraphDB在此基础上更进一步，允许一条边线指向其它边线，如此一来HyperGraphDB在概括性方面就大大超过了其它图形类数据库。下图显示的就是四条边线在超图形实例中的情况，各边线以不同颜色加以区分。
![](http://www.linuxidc.com/upload/2012_02/120208065783071.png)
* InfoGrid: InfoGrid是一款“网页图形数据库”，也就是说它的某些功能主要面向网页应用程序。下图展示了InfoGrid的整体框架，而图形数据库在其中所扮演的似乎并不是主要组成部分。InfoGrid在OpenID项目中也拥有几款应用程序，该项目由Netmesh公司所支持。
![](http://www.linuxidc.com/upload/2012_02/120208065783072.png)

从上面可以看到，

# 总结

本文调研了常用的大数据基础设施，按不同分类对其进行了详细介绍。可以看出，这些基础设施是互有交叉的，比如Spark既可以是批量数据处理系统也可以是流式数据处理系统同时又可用于图数据处理。同时，各种专业化基础设施层出不穷，但他们共同特点都是充分利用现有计算资源，通过大量服务器构成计算集群而不是专注于提升单机性能，并且大多数新出现基础设施都不是为了取代Hadoop而是对其的改进或者功能的延伸。

# 参考文献

[1] 1程学旗 2 靳小龙 3 王元卓 4 郭嘉丰 5 张铁赢 6 李国杰，大数据系统和分析技术综述,[J]软件学报,2014(2):1889~1908
[2] 俞立平, 大数据与大数据经济学[J], 中国软科学,2013(7):177—183
[3] 1 刘云生 2 代一尘 3 邓华锋, 流数据处理系统自适应机制研究[M], 第二十三届中国数据库学术会议论文集,2006
[4] 1 Alvarez 2 Carlos,NetApp deduplication for FAS and V-Series deployment and implementation guide[J], Technical ReportTR-3505,2011
[5] 1 Dumbill 2 Edd, What is big data[J], An introduction to the big data landscape,2012
[6] Apache, apache hive[E/B], http://hive.apache.org/
[7] Wikipedia,ApacheSpark[E/B],https://en.wikipedia.org/wiki/Apache_Spark
[8] Wikipedia,apacheHadoop[E/B],https://en.wikipedia.org/wiki/Apache_Hadoop
[9] Wikipedia,ApacheStorm[E/B],https://en.wikipedia.org/wiki/Apache_Storm
[10] 陈利人, Google Dremel 原理-如何能 3 秒分析 1PB [E/B], http://www.oschina.net/question/12_76159
[11] TonySicilian, 流式大数据处理的三种框架：Storm，Spark和Samza [E/B], http://www.csdn.net/article/2015-03-09/2824135
[12] 彩色蚂蚁, 快速理解SAMZA, streaming on kafka [E/B], http://blog.csdn.net/colorant/article/details/12082145
[13] 彩色蚂蚁, 快速理解Kafka分布式消息队列框架[E/B], http://blog.csdn.net/colorant/article/details/12081909,2013-09-27
[14] Andrew C. Oliver, Storm or Spark: Choose your real-time weapon[E/B], http://www.infoworld.com/article/2854894/application-development/spark-and-storm-for-real-time-computation.html,2014-12-04
[15] 成富, 图形数据库 Neo4j 开发实战[E/B], http://www.ibm.com/developerworks/cn/java/j-lo-neo4j/,2013-06-20
[16] Borislav Iordanov, HyperGraphDB - Data Management for Complex Systems[E/B], https://www.infoq.com/presentations/HyperGraphDB/,2010-05-10
[17] Wikistart, The Web Graph Database[E/B], http://infogrid.org/trac/
